{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "\n",
    "TBD...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"../input/cassava-model/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "TEST_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    num_workers = 4\n",
    "    models = [\n",
    "        # \"tf_efficientnet_b3_ns\",\n",
    "        \"tf_efficientnet_b4_ns\",\n",
    "        # \"vit_base_patch16_384\",\n",
    "        # \"deit_base_patch16_384\",\n",
    "        \"seresnext50_32x4d\",\n",
    "    ]\n",
    "    size = {\n",
    "        \"tf_efficientnet_b3_ns\": 512,\n",
    "        \"tf_efficientnet_b4_ns\": 512,\n",
    "        \"vit_base_patch16_384\": 384,\n",
    "        \"deit_base_patch16_384\": 384,\n",
    "        \"seresnext50_32x4d\": 512,\n",
    "    }\n",
    "    batch_size = 32\n",
    "    seed = 22\n",
    "    target_size = 5\n",
    "    target_col = \"label\"\n",
    "    n_fold = 5\n",
    "    trn_fold = {  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        \"tf_efficientnet_b3_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"tf_efficientnet_b4_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"vit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"deit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"seresnext50_32x4d\": {\"best\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"final\": []},\n",
    "    }\n",
    "    data_parallel = {\n",
    "        \"tf_efficientnet_b3_ns\": False,\n",
    "        \"tf_efficientnet_b4_ns\": True,\n",
    "        \"vit_base_patch16_384\": False,\n",
    "        \"deit_base_patch16_384\": False,\n",
    "        \"seresnext50_32x4d\": False,\n",
    "    }\n",
    "    weight = {\n",
    "        # \"tf_efficientnet_b3_ns\": None,\n",
    "        \"tf_efficientnet_b4_ns\": 1,\n",
    "        \"vit_base_patch16_384\": 1,\n",
    "        # \"deit_base_patch16_384\": None,\n",
    "        \"seresnext50_32x4d\": 2,\n",
    "    }\n",
    "    tta = 1  # 1: no TTA, >1: TTA\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sum = sum([CFG.weight[model] for model in CFG.models]) * CFG.tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorch-image-models/pytorch-image-models-master\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from albumentations import (\n",
    "    CenterCrop,\n",
    "    CoarseDropout,\n",
    "    Compose,\n",
    "    Cutout,\n",
    "    HorizontalFlip,\n",
    "    HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise,\n",
    "    ImageOnlyTransform,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomContrast,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    Transpose,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"inference.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"image_id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{TEST_PATH}/{file_name}\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data, size):\n",
    "\n",
    "    if data == \"train\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                ShiftScaleRotate(p=0.5),\n",
    "                HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                CoarseDropout(p=0.5),\n",
    "                Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"valid\":\n",
    "        return Compose(\n",
    "            [\n",
    "                Resize(size, size),\n",
    "                CenterCrop(size, size),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"inference\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                # ShiftScaleRotate(p=0.5),\n",
    "                # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                # RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                # CoarseDropout(p=0.5),\n",
    "                # Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnext50_32x4d\", pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"deit_base_patch16_384\":\n",
    "            # self.model = torch.hub.load(\"facebookresearch/deit:main\", model_name, pretrained=pretrained)\n",
    "            self.model = torch.hub.load(\"../input/fair-deit\", model_name, pretrained=pretrained, source=\"local\")\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "        else:\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "            if \"resnext50_32x4d\" in model_name:\n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"tf_efficientnet\"):\n",
    "                n_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"vit_\"):\n",
    "                n_features = self.model.head.in_features\n",
    "                self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "def inference(model, states, test_loader, device, data_parallel):\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and data_parallel:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: tf_efficientnet_b4_ns, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b38e759ffa48f2be13864ad0ec66bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.4113303  0.16465071 0.19031808 0.01710353 0.21659732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: seresnext50_32x4d, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff50968eee34a92b3361f219da9d550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.35461578 0.36254448 0.09223738 0.01939635 0.17120597]\n",
      "========== Overall ==========\n",
      "Submission example: [0.3735206  0.29657987 0.12493094 0.01863208 0.18633641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      4\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "predictions = None\n",
    "for model_name in CFG.models:\n",
    "    for i in range(CFG.tta):\n",
    "        model = CassvaImgClassifier(model_name, pretrained=False)\n",
    "        states = []\n",
    "        for saved_model in [\"best\", \"final\"]:\n",
    "            if CFG.trn_fold[model_name][saved_model] != []:\n",
    "                LOGGER.info(\n",
    "                    f\"========== Model: {model_name}, TTA: {i}, Saved: {saved_model}, Fold: {CFG.trn_fold[model_name][saved_model]} ==========\"\n",
    "                )\n",
    "                states += [\n",
    "                    torch.load(MODEL_DIR + f\"{model_name}_fold{fold}_{saved_model}.pth\")\n",
    "                    for fold in CFG.trn_fold[model_name][saved_model]\n",
    "                ]\n",
    "\n",
    "        if i == 0:  # no TTA\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"valid\", size=CFG.size[model_name]))\n",
    "        else:\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"inference\", size=CFG.size[model_name]))\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "        inf = inference(model, states, test_loader, device, CFG.data_parallel[model_name])\n",
    "\n",
    "        LOGGER.info(f\"Inference example: {inf[0]}\")\n",
    "\n",
    "        if predictions is None:\n",
    "            predictions = inf[np.newaxis] * CFG.weight[model_name]\n",
    "        else:\n",
    "            predictions = np.append(predictions, inf[np.newaxis] * CFG.weight[model_name], axis=0)\n",
    "\n",
    "sub = np.sum(predictions, axis=0) / weight_sum\n",
    "LOGGER.info(f\"========== Overall ==========\")\n",
    "LOGGER.info(f\"Submission example: {sub[0]}\")\n",
    "np.savetxt(f\"{OUTPUT_DIR}/predictions.csv\", sub, delimiter=\",\")\n",
    "\n",
    "# submission\n",
    "test[\"label\"] = sub.argmax(1)\n",
    "test[[\"image_id\", \"label\"]].to_csv(OUTPUT_DIR + \"submission.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train[\"label\"], test[\"label\"])\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.savefig(f\"images/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82      1087\n",
      "           1       0.93      0.88      0.91      2189\n",
      "           2       0.90      0.88      0.89      2386\n",
      "           3       0.97      0.99      0.98     13158\n",
      "           4       0.86      0.85      0.86      2577\n",
      "\n",
      "    accuracy                           0.94     21397\n",
      "   macro avg       0.90      0.88      0.89     21397\n",
      "weighted avg       0.94      0.94      0.94     21397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train[\"label\"], test[\"label\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
