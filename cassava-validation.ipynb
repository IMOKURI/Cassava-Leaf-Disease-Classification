{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "\n",
    "TBD...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"../input/cassava-model/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "TEST_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    num_workers = 4\n",
    "    models = [\n",
    "        # \"tf_efficientnet_b3_ns\",\n",
    "        \"tf_efficientnet_b4_ns\",\n",
    "        # \"vit_base_patch16_384\",\n",
    "        # \"deit_base_patch16_384\",\n",
    "        \"seresnext50_32x4d\",\n",
    "    ]\n",
    "    size = {\n",
    "        \"tf_efficientnet_b3_ns\": 512,\n",
    "        \"tf_efficientnet_b4_ns\": 512,\n",
    "        \"vit_base_patch16_384\": 384,\n",
    "        \"deit_base_patch16_384\": 384,\n",
    "        \"seresnext50_32x4d\": 512,\n",
    "    }\n",
    "    batch_size = 32\n",
    "    seed = 22\n",
    "    target_size = 5\n",
    "    target_col = \"label\"\n",
    "    n_fold = 5\n",
    "    trn_fold = {  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        \"tf_efficientnet_b3_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"tf_efficientnet_b4_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"vit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"deit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"seresnext50_32x4d\": {\"best\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"final\": []},\n",
    "    }\n",
    "    data_parallel = {\n",
    "        \"tf_efficientnet_b3_ns\": False,\n",
    "        \"tf_efficientnet_b4_ns\": True,\n",
    "        \"vit_base_patch16_384\": False,\n",
    "        \"deit_base_patch16_384\": False,\n",
    "        \"seresnext50_32x4d\": False,\n",
    "    }\n",
    "    weight = {\n",
    "        # \"tf_efficientnet_b3_ns\": None,\n",
    "        \"tf_efficientnet_b4_ns\": 1,\n",
    "        \"vit_base_patch16_384\": 1,\n",
    "        # \"deit_base_patch16_384\": None,\n",
    "        \"seresnext50_32x4d\": 2,\n",
    "    }\n",
    "    tta = 1  # 1: no TTA, >1: TTA\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sum = sum([CFG.weight[model] for model in CFG.models]) * CFG.tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorch-image-models/pytorch-image-models-master\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from albumentations import (\n",
    "    CenterCrop,\n",
    "    CoarseDropout,\n",
    "    Compose,\n",
    "    Cutout,\n",
    "    HorizontalFlip,\n",
    "    HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise,\n",
    "    ImageOnlyTransform,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomContrast,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    Transpose,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"inference.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"image_id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{TEST_PATH}/{file_name}\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data, size):\n",
    "\n",
    "    if data == \"train\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                ShiftScaleRotate(p=0.5),\n",
    "                HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                CoarseDropout(p=0.5),\n",
    "                Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"valid\":\n",
    "        return Compose(\n",
    "            [\n",
    "                Resize(size, size),\n",
    "                CenterCrop(size, size),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"inference\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                # ShiftScaleRotate(p=0.5),\n",
    "                # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                # RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                # CoarseDropout(p=0.5),\n",
    "                # Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnext50_32x4d\", pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"deit_base_patch16_384\":\n",
    "            # self.model = torch.hub.load(\"facebookresearch/deit:main\", model_name, pretrained=pretrained)\n",
    "            self.model = torch.hub.load(\"../input/fair-deit\", model_name, pretrained=pretrained, source=\"local\")\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "        else:\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "            if \"resnext50_32x4d\" in model_name:\n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"tf_efficientnet\"):\n",
    "                n_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"vit_\"):\n",
    "                n_features = self.model.head.in_features\n",
    "                self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "def inference(model, states, test_loader, device, data_parallel):\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and data_parallel:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: tf_efficientnet_b4_ns, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaca61a11ef4998b29a472673d55522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.4113303  0.16465071 0.19031808 0.01710353 0.21659732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: seresnext50_32x4d, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b9d74a27e743eb86b89a2d590b78f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.35461578 0.36254448 0.09223738 0.01939635 0.17120597]\n",
      "========== Overall ==========\n",
      "Inference example: [0.35461578 0.36254448 0.09223738 0.01939635 0.17120597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      1\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      4\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "predictions = None\n",
    "for model_name in CFG.models:\n",
    "    for i in range(CFG.tta):\n",
    "        model = CassvaImgClassifier(model_name, pretrained=False)\n",
    "        states = []\n",
    "        for saved_model in [\"best\", \"final\"]:\n",
    "            if CFG.trn_fold[model_name][saved_model] != []:\n",
    "                LOGGER.info(\n",
    "                    f\"========== Model: {model_name}, TTA: {i}, Saved: {saved_model}, Fold: {CFG.trn_fold[model_name][saved_model]} ==========\"\n",
    "                )\n",
    "                states += [\n",
    "                    torch.load(MODEL_DIR + f\"{model_name}_fold{fold}_{saved_model}.pth\")\n",
    "                    for fold in CFG.trn_fold[model_name][saved_model]\n",
    "                ]\n",
    "\n",
    "        if i == 0:  # no TTA\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"valid\", size=CFG.size[model_name]))\n",
    "        else:\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"inference\", size=CFG.size[model_name]))\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "        inf = inference(model, states, test_loader, device, CFG.data_parallel[model_name])\n",
    "\n",
    "        LOGGER.info(f\"Inference example: {inf[0]}\")\n",
    "\n",
    "        if predictions is None:\n",
    "            predictions = inf[np.newaxis] * CFG.weight[model_name]\n",
    "        else:\n",
    "            predictions = np.append(predictions, inf[np.newaxis] * CFG.weight[model_name], axis=0)\n",
    "\n",
    "sub = np.sum(predictions, axis=0) / weight_sum\n",
    "LOGGER.info(f\"========== Overall ==========\")\n",
    "LOGGER.info(f\"Submission example: {sub[0]}\")\n",
    "np.savetxt(f\"{OUTPUT_DIR}/predictions.csv\", sub, delimiter=\",\")\n",
    "\n",
    "# submission\n",
    "test[\"label\"] = sub.argmax(1)\n",
    "test[[\"image_id\", \"label\"]].to_csv(OUTPUT_DIR + \"submission.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train[\"label\"], test[\"label\"])\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.savefig(f\"images/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1087\n",
      "           1       0.93      0.89      0.91      2189\n",
      "           2       0.91      0.89      0.90      2386\n",
      "           3       0.97      0.99      0.98     13158\n",
      "           4       0.88      0.86      0.87      2577\n",
      "\n",
      "    accuracy                           0.94     21397\n",
      "   macro avg       0.91      0.89      0.90     21397\n",
      "weighted avg       0.94      0.94      0.94     21397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train[\"label\"], test[\"label\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
