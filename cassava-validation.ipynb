{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "\n",
    "TBD...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"../input/cassava-model/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "TEST_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    num_workers = 4\n",
    "    models = [\n",
    "        # \"tf_efficientnet_b3_ns\",\n",
    "        # \"tf_efficientnet_b4_ns\",\n",
    "        # \"vit_base_patch16_384\",\n",
    "        # \"deit_base_patch16_384\",\n",
    "        \"seresnext50_32x4d\",\n",
    "    ]\n",
    "    size = {\n",
    "        \"tf_efficientnet_b3_ns\": 512,\n",
    "        \"tf_efficientnet_b4_ns\": 512,\n",
    "        \"vit_base_patch16_384\": 384,\n",
    "        \"deit_base_patch16_384\": 384,\n",
    "        \"seresnext50_32x4d\": 512,\n",
    "    }\n",
    "    batch_size = 32\n",
    "    seed = 22\n",
    "    target_size = 5\n",
    "    target_col = \"label\"\n",
    "    n_fold = 5\n",
    "    trn_fold = {  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        \"tf_efficientnet_b3_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"tf_efficientnet_b4_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"vit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"deit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"seresnext50_32x4d\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "    }\n",
    "    data_parallel = {\n",
    "        \"tf_efficientnet_b3_ns\": False,\n",
    "        \"tf_efficientnet_b4_ns\": True,\n",
    "        \"vit_base_patch16_384\": False,\n",
    "        \"deit_base_patch16_384\": False,\n",
    "        \"seresnext50_32x4d\": False,\n",
    "    }\n",
    "    tta = 1  # 1: no TTA, >1: TTA\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorch-image-models/pytorch-image-models-master\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from albumentations import (\n",
    "    CenterCrop,\n",
    "    CoarseDropout,\n",
    "    Compose,\n",
    "    Cutout,\n",
    "    HorizontalFlip,\n",
    "    HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise,\n",
    "    ImageOnlyTransform,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomContrast,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    Transpose,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"inference.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"image_id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{TEST_PATH}/{file_name}\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data, size):\n",
    "\n",
    "    if data == \"train\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                ShiftScaleRotate(p=0.5),\n",
    "                HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                CoarseDropout(p=0.5),\n",
    "                Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"valid\":\n",
    "        return Compose(\n",
    "            [\n",
    "                Resize(size, size),\n",
    "                CenterCrop(size, size),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"inference\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                # Transpose(p=0.5),\n",
    "                # HorizontalFlip(p=0.5),\n",
    "                # VerticalFlip(p=0.5),\n",
    "                # ShiftScaleRotate(p=0.5),\n",
    "                # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                # RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                # CoarseDropout(p=0.5),\n",
    "                # Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnext50_32x4d\", pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"deit_base_patch16_384\":\n",
    "            # self.model = torch.hub.load(\"facebookresearch/deit:main\", model_name, pretrained=pretrained)\n",
    "            self.model = torch.hub.load(\"../input/fair-deit\", model_name, pretrained=pretrained, source=\"local\")\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "        else:\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "            if \"resnext50_32x4d\" in model_name:\n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"tf_efficientnet\"):\n",
    "                n_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"vit_\"):\n",
    "                n_features = self.model.head.in_features\n",
    "                self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "def inference(model, states, test_loader, device, data_parallel):\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and data_parallel:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: seresnext50_32x4d, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dab45654ee4a4081bb44f8ac184625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.41019613 0.33533946 0.08603122 0.01322082 0.15521245]\n",
      "========== Overall ==========\n",
      "Inference example: [0.41019613 0.33533946 0.08603122 0.01322082 0.15521245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      4\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "for model_name in CFG.models:\n",
    "    for i in range(CFG.tta):\n",
    "        model = CassvaImgClassifier(model_name, pretrained=False)\n",
    "        states = []\n",
    "        for saved_model in [\"best\", \"final\"]:\n",
    "            if CFG.trn_fold[model_name][saved_model] != []:\n",
    "                LOGGER.info(\n",
    "                    f\"========== Model: {model_name}, TTA: {i}, Saved: {saved_model}, Fold: {CFG.trn_fold[model_name][saved_model]} ==========\"\n",
    "                )\n",
    "                states += [\n",
    "                    torch.load(MODEL_DIR + f\"{model_name}_fold{fold}_{saved_model}.pth\")\n",
    "                    for fold in CFG.trn_fold[model_name][saved_model]\n",
    "                ]\n",
    "\n",
    "        if i == 0:  # no TTA\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"valid\", size=CFG.size[model_name]))\n",
    "        else:\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"inference\", size=CFG.size[model_name]))\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "        inf = inference(model, states, test_loader, device, CFG.data_parallel[model_name])\n",
    "\n",
    "        LOGGER.info(f\"Inference example: {inf[0]}\")\n",
    "\n",
    "        if i == 0:\n",
    "            predictions = inf[np.newaxis]\n",
    "        else:\n",
    "            predictions = np.append(predictions, inf[np.newaxis], axis=0)\n",
    "\n",
    "sub = np.mean(predictions, axis=0)\n",
    "LOGGER.info(f\"========== Overall ==========\")\n",
    "LOGGER.info(f\"Inference example: {sub[0]}\")\n",
    "\n",
    "# submission\n",
    "test[\"label\"] = sub.argmax(1)\n",
    "test[[\"image_id\", \"label\"]].to_csv(OUTPUT_DIR + \"submission.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train[\"label\"], test[\"label\"])\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.savefig(f\"images/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      1087\n",
      "           1       0.93      0.89      0.91      2189\n",
      "           2       0.91      0.89      0.90      2386\n",
      "           3       0.97      0.99      0.98     13158\n",
      "           4       0.87      0.86      0.87      2577\n",
      "\n",
      "    accuracy                           0.94     21397\n",
      "   macro avg       0.91      0.89      0.90     21397\n",
      "weighted avg       0.94      0.94      0.94     21397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train[\"label\"], test[\"label\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
