{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "\n",
    "TBD...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"../input/cassava-model/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "TEST_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    num_workers = 4\n",
    "    models = [\n",
    "        # \"tf_efficientnet_b3_ns\",\n",
    "        # \"tf_efficientnet_b4_ns\",\n",
    "        # \"vit_base_patch16_384\",\n",
    "        # \"deit_base_patch16_384\",\n",
    "        \"seresnext50_32x4d\",\n",
    "    ]\n",
    "    size = {\n",
    "        \"tf_efficientnet_b3_ns\": 512,\n",
    "        \"tf_efficientnet_b4_ns\": 512,\n",
    "        \"vit_base_patch16_384\": 384,\n",
    "        \"deit_base_patch16_384\": 384,\n",
    "        \"seresnext50_32x4d\": 512,\n",
    "    }\n",
    "    batch_size = 32\n",
    "    seed = 22\n",
    "    target_size = 5\n",
    "    target_col = \"label\"\n",
    "    n_fold = 5\n",
    "    trn_fold = {  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        \"tf_efficientnet_b3_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"tf_efficientnet_b4_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"vit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"deit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"seresnext50_32x4d\": {\"best\": [5, 6, 7, 8, 9], \"final\": []},\n",
    "    }\n",
    "    data_parallel = {\n",
    "        \"tf_efficientnet_b3_ns\": False,\n",
    "        \"tf_efficientnet_b4_ns\": True,\n",
    "        \"vit_base_patch16_384\": False,\n",
    "        \"deit_base_patch16_384\": False,\n",
    "        \"seresnext50_32x4d\": False,\n",
    "    }\n",
    "    tta = 1  # 1: no TTA, >1: TTA\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorch-image-models/pytorch-image-models-master\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from albumentations import (\n",
    "    CenterCrop,\n",
    "    CoarseDropout,\n",
    "    Compose,\n",
    "    Cutout,\n",
    "    HorizontalFlip,\n",
    "    HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise,\n",
    "    ImageOnlyTransform,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomContrast,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    Transpose,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"inference.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"image_id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{TEST_PATH}/{file_name}\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data, size):\n",
    "\n",
    "    if data == \"train\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                ShiftScaleRotate(p=0.5),\n",
    "                HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                CoarseDropout(p=0.5),\n",
    "                Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"valid\":\n",
    "        return Compose(\n",
    "            [\n",
    "                Resize(size, size),\n",
    "                CenterCrop(size, size),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"inference\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                # Transpose(p=0.5),\n",
    "                # HorizontalFlip(p=0.5),\n",
    "                # VerticalFlip(p=0.5),\n",
    "                # ShiftScaleRotate(p=0.5),\n",
    "                # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                # RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                # CoarseDropout(p=0.5),\n",
    "                # Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnext50_32x4d\", pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"deit_base_patch16_384\":\n",
    "            # self.model = torch.hub.load(\"facebookresearch/deit:main\", model_name, pretrained=pretrained)\n",
    "            self.model = torch.hub.load(\"../input/fair-deit\", model_name, pretrained=pretrained, source=\"local\")\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "        else:\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "            if \"resnext50_32x4d\" in model_name:\n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"tf_efficientnet\"):\n",
    "                n_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"vit_\"):\n",
    "                n_features = self.model.head.in_features\n",
    "                self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "def inference(model, states, test_loader, device, data_parallel):\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and data_parallel:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: seresnext50_32x4d, TTA: 0, Saved: best, Fold: [5, 6, 7, 8, 9] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9678c399e95f46d39b7926503d93fda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=669.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.2990355  0.3897496  0.09844354 0.02557188 0.1871995 ]\n",
      "========== Overall ==========\n",
      "Inference example: [0.2990355  0.3897496  0.09844354 0.02557188 0.1871995 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      1\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      4\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "for model_name in CFG.models:\n",
    "    for i in range(CFG.tta):\n",
    "        model = CassvaImgClassifier(model_name, pretrained=False)\n",
    "        states = []\n",
    "        for saved_model in [\"best\", \"final\"]:\n",
    "            if CFG.trn_fold[model_name][saved_model] != []:\n",
    "                LOGGER.info(\n",
    "                    f\"========== Model: {model_name}, TTA: {i}, Saved: {saved_model}, Fold: {CFG.trn_fold[model_name][saved_model]} ==========\"\n",
    "                )\n",
    "                states += [\n",
    "                    torch.load(MODEL_DIR + f\"{model_name}_fold{fold}_{saved_model}.pth\")\n",
    "                    for fold in CFG.trn_fold[model_name][saved_model]\n",
    "                ]\n",
    "\n",
    "        if i == 0:  # no TTA\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"valid\", size=CFG.size[model_name]))\n",
    "        else:\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"inference\", size=CFG.size[model_name]))\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "        inf = inference(model, states, test_loader, device, CFG.data_parallel[model_name])\n",
    "\n",
    "        LOGGER.info(f\"Inference example: {inf[0]}\")\n",
    "\n",
    "        if i == 0:\n",
    "            predictions = inf[np.newaxis]\n",
    "        else:\n",
    "            predictions = np.append(predictions, inf[np.newaxis], axis=0)\n",
    "\n",
    "sub = np.mean(predictions, axis=0)\n",
    "LOGGER.info(f\"========== Overall ==========\")\n",
    "LOGGER.info(f\"Inference example: {sub[0]}\")\n",
    "\n",
    "# submission\n",
    "test[\"label\"] = sub.argmax(1)\n",
    "test[[\"image_id\", \"label\"]].to_csv(OUTPUT_DIR + \"submission.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train[\"label\"], test[\"label\"])\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD4CAYAAABPLjVeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7ZElEQVR4nO3deXxM1/vA8c/JZk9iScaS8C3RWqKqRXeSkAWRxVa0dNdVVdW+tKUURVFLSyntt8vXFoIQaitaWxc7tVRJyCR2QSWZnN8fE5FJRIRkZszveXvN65U798yd53HnPjk59849SmuNEEII63CydQBCCPH/iRRdIYSwIim6QghhRVJ0hRDCiqToCiGEFbkU9xu4d/7G4S6PSPqmm61DKBZOTsrWIYjblJaRaesQioV7ybv/EJZq9PZt15yrf0yx+odeerpCCGFFxd7TFUIIq1L23ZeUoiuEcCxOzraO4Jak6AohHIuy73MTUnSFEI5FhheEEMKKpKcrhBBWJD1dIYSwIunpCiGEFcnVC0IIYUUyvCCEEFYkwwtCCGFF0tMVQggrkqIrhBBW5Cwn0oQQwnpkTFcIIaxIhheEEMKK7Lyna9+/EnJo2bAqv02I5M+JUfSO8M+z3qdiGZYNDWHjJ+H8MqYtIQ9Vy7P+5Jwu9AyvZ62Qb2rzpo1EtQ0jonUIs7+akWd9Wloa/d/vTUTrELp17cTJxAQAzp8/x6svdeeJpg8zeuRwi9ekp6cx4sOhRIaHEt22FT+tji/+PDb+TESbUMLDgpk18+Z59O3zLuFhwTzbuSOJWXkAzJr5JeFhwUS0CWXzpo3Zz7cKDqJ9VFs6tYukS6d2ebY5d85sGtZ/gHPnzhZPUhR9XkmnTvHyC92Ibtua6Ig2fPftXJvkldMvmzfSPqIV0eGhzJk1M8/6tLQ0BvbtTXR4KC88+wwnExMB2Lt7F107RZsfHaNYt2Z19msuXbxI/z696BDZmo5Rbdi18w+r5HJTyun2HzZwT/R0nZRi/EuPEjlyNYlnrrB+VGvifjvBwcQL2W36tmtAzJZjzFr9Fw9U82DBgBY06Lkoe/2o7o1Z/WeiLcLPZjKZGD1yONNnzMZQ2cCznTvSPDCIWrX8stssXrSAcu7uxMatYuWK5Uz6bDxjxn1GCbcSvPl2Lw4fPsSRQ39ZbPerGV9QoUJFliyLJzMzkwsXLuR+6yLPY9TI4Xw582sMBgNdn+lAQGAQtfxu5BGzcD7u7u4sW7maFXHLmThhHJ+On8iRw4dZGbecRbHLSU428torLxK7PB7nrJMfX309l/LlK+R5z6RTp/h182aqVKl6b+Xl4sz7/QZQt159Ll9OpXPH9jz2+JPZ27RGXrlzHDtqBFO+nIXBYOD5rp1oFhBIzRyfwSUxC3B39yBmWTyrVizn84nj+OTTz6jlV5tvvp+Pi4sLp1OS6doxmqebB+Li4sL4saN4/MmnGDN+Eunpafx79V+r5HNT93pPVylVRynVXyk1OevRXylV1xrBXdfYryJHky5xLDmVdFMmC385RpvGvhZttIZypVwB8CjtStK5K9nr2jT25Z/kVA4kFG8xKsie3bvwrV4dH19fXF3dCG3VmvXr1li0Wb9uDW0jogBoGRzKtq2/orWmVOnSNHr4EUq4ueXZ7pKYRbz0Sg8AnJycKF++fPHn4VvDnIebG2Gt2+TJY93atURERgMQHBLKti3mPNavW0NY6za4ubnh4+OLr28N9uzeVeB7fjrmE3r36YsqxgOqOPLy8vKmbr36AJQpU5aaNWuSnGy0al457d2zC1/f6vj4mD+DwWGt2bB+rUWbn9etpU1EJABBwaFs37YFrTUlS5XCxcXcT7t2LS075tRLl/jjtx1ERncAwNXVjXLu7lbJ56acnG//YYvwbrVSKdUf+BFQwLashwJ+UEoNKP7wzKpUKE3CmcvZyyfPXqFqhdIWbT5ZsJNnnqrJ/qntmd+/BX2/3gZAmRIu9I7wZ/SCndYKN1/JyUYMlatkLxsMlUkxGnO1SaZyVhsXFxfKli3H+fPn893mpYsXAZg6ZRJdOrWj73u9OHP6dNEHnzNGo5HKVSpnL3sbDBjz5GG0zKNcOc6fP4fRaMRQ+cZrDZUNJF9/rYLXX32Zzh3bsWDe/7LbrFv7E94Gbx6oU6cYsyrGvLIkJiZwYP9+GjzYELBeXjmlJCdbxultuMln8Mbn9Ppn8ELWZ3DPrp10ig6nS4dIBgz5ABcXFxITE/AsX4GPhg3i2U7t+PjDIVy9cgWbsfPhhYLe9WWgidZ6tNb6v1mP0UDTrHU3pZTqoZTaoZTakXZkXVHGm68OT/yH7zYcoe5bC+k4Zg0z3noKpWBgx4ZMjdvH5WsZVonD2jJMJozGJBo+1Igf5i3iwYYP8dn4sbYO647M+fYH/rcghqlfzOR/P3zHbzu2c/XqVb6a8SVvvt3L1uHdlSuXL9Pn3XfoO2AQZcuWvWfz8n+wIfNiljH3+3nMmTWTa9euYTKZOHhgHx06dua7eYsoWao0c2bnHSu2GqVu/2EDBRXdTOBmg01VstbdlNZ6hta6sda6sVutwLuJD4BTZ6/gU7FM9nLVCqU5edbyN2n3wNrEbDkGwLZDpynh6kzFciVp7FeJ4c8+wu7P2/FGq7q8H9WAHqEP3HVMd8Lb24Ax6VT2stGYhJfBkKuNN0lZbTIyMkhNvYSnp2e+2/T09KRkqVK0aBkCQHBoGPv37yv64HPGaDCQdCopeznZaMSQJw+DZR6XLuHpWR6DwYAx6cZrjUlGvLNee30bFStWJKhlMHt27yLhxHESExPo1C6SVsFBGI1JdO7QjtMpKfdMXunp6bz37ju0btOWlsHm/WTNvHLy8va2jDPZeJPP4I3P6fXPoEeuz+B9NWtRunRpjhw+hLfBgLfBgH9WD75FcAgHDxTvZ/CW7vGe7rvAGqXUCqXUjKzHSmANYLVf0b8dOUPNyuWo4VUWV2cn2j/xH+J+O2HRJuHMZZr7m/8kur+qByVdnTl98V/CPoynQc9FNOi5iOkr9jNu8W5mxB+0VugW6vs34Pg//5CYkEB6ehrxK+IICAiyaNM8IIilsYsB+Gl1PE2aPnbL8T6lFM2aB7Jju3k4ZduWX6lZs1ax5QBZeRw/RkLCCdLT0lgZt5zmgZZ5BAQGEbskBoDVq+Jp+qg5j+aBQayMW05aWhoJCSc4fvwY/g0e5MqVK1y+nArAlStX+PWXzfj51ab2/Q+wfuOvrFi9lhWr12IwVObHBYuo5OV1T+SltebDYYOpWbMm3V94MXs71swrp3r1G3D8+I3P4OqVcTRrbtkxejogkOWxSwBYm+MzmJiQQEaG+S/GUycTOXbsKFWrVqNSJS8MhiocO/Y3ANu3buG+mn7YjJ0X3VtevaC1XqmUuh/zcML1a7ASge1aa1NxB3edKVPT9+ttxAxqibOT4tt1hzmQcIHBHRvy+9EzrPgtgUHf7uDzHo/zVuu6aA1vfLHZWuHdNhcXF/oPGsqbr79MpimTyOj21PKrzbQpk6lX35+AwCCi2nVgyMB+RLQOwd3Dg9FjJ2S/vnVoEJdTL5Oens66tWuYNmMWtWr50at3H4YM7M+4MaMoX6ECH44YVex5DBw8jDd6vEJmpomo6Pb4+dVm6ueTqF/fn4CgFkS378DgAX0JDwvG3cODseM+A8DPrzYhYa2IjmiNs7Mzg4YMw9nZmbNnztD7nbcA85BJ6zbhPPl0s2LNwxp5/f7bDpbFLqH2/ffTqZ355FTPd9/j6WbNrZpbzhz7DRzCO2+8gikzk4iodtTyq80XUydTt74/zQOCiIzuwAeD+xMdHoq7uwcjx44HYOcfvzFn9kxcXF1xUor+g4bhmXXS9v0Bgxk2sC/p6elU8/Fl2PCRNskPsPv76SqtdbG+gXvnb4r3DWwg6Ztutg6hWDg52felNuKGtIx8R/fuae4l7/5DWCpqxm3XnKuLe1j9Q39PXKcrhBC3Tb4GLIQQVmTnX46QoiuEcCjW+qLJnZKiK4RwKFJ0hRDCipSdnxCWoiuEcCjS0xVCCCuSoiuEEFYkRVcIIazJvmuuFF0hhGORnq4QQliRk5N8I00IIazG3nu69v0rQQghCksV4lHQppQKU0odVEodvtlsOUqp6kqpdUqpP5RSu5RSrQvaphRdIYRDUUrd9qOA7TgDU4FWQD2gi1Iq93TiQ4B5WutGQGdgWkHxSdEVQjiUoiq6mO8jflhrfVRrnYZ5vsjIXG00cH0WTg/gZEEblTFdIYRDKczXgJVSPYAeOZ6aobWekfVzNSDnFDUJwKO5NvEhsEop1RMoA7Qs6D2Lvej+Patrcb+F1VWMmmzrEIrFmSXv2DqEIudk5ydVRNErzIm0rAI7o8CG+esCzNFaj1dKPQ58q5Ty11rne5d56ekKIRxKEV69kAj45lj2yXoup5eBMACt9a9KqZJAJSA5v43KmK4QwqEU4ZjudqC2Uuo+pZQb5hNlsbnaHAdaZL1vXaAkcMspnaWnK4RwKEXV09VaZyil3gbiAWdgttZ6r1JqOLBDax0L9AFmKqV6Yz6p9oIuYOJJKbpCCMdShMP4Wus4IC7Xc8Ny/LwPeLIw25SiK4RwKPI1YCGEsCJ7/xqwFF0hhGOx75orRVcI4VikpyuEEFYkRVcIIaxIiq4QQliRTMEuhBBWJD1dIYSwIim6QghhRXZec6XoCiEci/R0hRDCipzkRJoQQliPnXd07bfobtm8kYnjRmMymWgb3Z7uL75qsT4tLY0RQwdyYP9ePDw9GTF6PFWqVuPUyUS6tG9LjRr/AaB+g4b0G/wBAKtWLueb2TNRKCp5efHBx2PwLF/e2qllC36kBuNea46zk2JO/F7Gzd9hsd7Xqxwz3wvGo2wJnJ2cGPr1ZuJ3HMPVxYkpPVvwcG1vMjM173+5gY27c99b2bo2b9rIp6NHkmnKJKp9B156pYfF+rS0NIYO7M/+feb9NWbcBKpW8+H8+XP07d2LvXv2EBEVxYDB2Tdw4q3XXiElJQWTyUSjhx9h4JBhODs7F28eG39mTFYe0e078vKrefMYPLAf+/ea8xg7/jOqVfMBYNbML4lZuAAnZyf6DxzCk089zbVr13ix+7Okp6WRYTIRHBLKm2+bZ+h4oVtXrly+DMDZs2fwb/AgEz8vcF7Du/bL5o2MHzOKzMxMIqM78MLLeY+tDwb358D+fXh4eDJq7ASqVqvG3t27GDnCfCyhNa++/haBLYKzX2cymejepSPe3t58NuWLYs8jP/be07XL2/GYTCbGjRnJ+M+/4PuFsfy0Mo6/jx62aLN08ULKubszP3YlzzzbnWmTJmSvq+bjy9wfFzH3x0XZBTcjI4OJn45mypdf8+28GPxq38+C/31v1bxycnJSTHwzgMhhi2n0+rd0bH4/dXwrWLTp37kJCzce4vGeP9B99AomvRUIwEth/gA0efM7wgfHMPqVp236291kMjH64+FMmT6ThbHLWBm3nCNHLPfX4kULKOfuTuyKVTzb7XkmTRgPQAm3ErzZsxe93++XZ7tjxk9k3qIlLFi8lHPnzrI6fmWx5zFq5HCmffEVMbHLWRm3jCOHLfOIWTgfd3d3lq1czXPdX2DihHEAHDl8mJVxy1kUu5xpX37FqI8/wmQy4ebmxlez5zI/JpZ5CxezedNGdu38E4A5337PvEVLmLdoCQ82bESLliHFmt/1HMeOGsGkaTOYF7OUVSuXczTXvloSswB3dw9ilsXT9bnufD7RnGMtv9p88/18vp8Xw+RpM/hkxIdkZGRkv+7H777lvpo1iz2Hgih1+w9bsMuiu2/Pbnx8fKnm44urqxstQ1uzcf06izYb16+lVbh5Ys7AFiHs2L6FW947WGvQmqtXr6K15vLly1Ty8irONG6pyf0Gjpy8wLGki6RnZDL/578If9zyA6s1uJd2A8CjjBunzqQCUKd6BdbvNM+Xl3LhKhcup/FIbYN1E8hhz+5d+Favjo+veX+FtmrN+rVrLNqsX7uGtpFRALQMCWXb1l/RWlOqdGkaPfwIJUq45dlu2bJlAfMvzIz09GI/QbJn9y58fWuY83BzI6x1G9avs8xj3dq1RERGAxAcEsq2LeY81q9bQ1jrNri5ueHj44uvbw327N6FUorSZcrcyCMjI8/RnpqayrZtWwhsUeCchndt755d+PpWxyfr2AoOa82G9Wst2vy8bi1tIszHVlBwKNu3mY+tkqVK4eJi/uP42rU0i/1hNCaxaeMGIqM7FHsOBSnCmSOKhV0W3ZQUI4bKVbKXvbwNpCQbc7VJxlC5MgAuLi6UKVuOC+fPA3AqMZHnu7TnzVee58/ffzO3cXXl/UFD6fZMFBGhAfx99Ahto9pbJ6GbqFqxLAmnL2UvJ55OpVrFshZtRn63hc5BdTj8zUvEfBTJe19sAGD30dOEP1oTZydFDYM7jfy88fEqZ9X4c0pOttxfBkPlPPsrOTmZylltXFxcKFu2HOez9tetvNnjZVo0f5LSZcrQMiS0SOPOLdlopHKVytnL3gYDRmPuPIyWeZQrx/nz5zAajdmfRwBDZQPJWa81mUx0ahdJ4NNP8NjjT/Dggw0ttrluzU88+ujj2b9kilNKcrJlnN4GUm6SoyHXvrp+bO3ZtZNO0eF06RDJgCEfZBfhCWM/4Z3e79vFvWwdtqerlHqxKAMpKhUreRET9xNzf1jIO+/148PB/bicmkpGejox8//HnO8XEBu/Hr/a9/PN1zNtHe4tdQp4gP+u3odf99lEf7CEWe+HoBTMXbWXxNOpbJ7UhU97NGPL/lOYMvOdfPSeNm3GLFav20haWhrbt26xdTh3xNnZmXmLlrBq7Qb27N7FoUN/WaxfEbeMVq3b2Ci6wvF/sCHzYpYx9/t5zJk1k2vXrrFxwzrKV6hA3Xr1bR0eYL6J+e0+bBLfXbz2o/xWKKV6KKV2KKV2zJ1d+MLm5WXAmHQqezkl2YiXtyFXG2+MSUmA+c+2y6mX8PD0xM3NDQ9PTwDq1KtPNR9fjh8/xl9/HQDAx7c6SimCgsPYkzW2Zgsnz6TiU+lG77RapbIkZg0fXPd8SH0WbjwEwNYDSZR0daGSeylMmZp+M3/msZ7f02nEMjzLuHEo4bw1w7fg7W25v4zGpDz7y9vbm6SsNhkZGaSmXsIzaz8VpESJEgQEtsjzp35R8zYYSDqVlL2cbDRiMOTOw2CZx6VLeHqWx2AwZH8eAYxJRrxzvdbd3Z0mTR/ll00bs587d+4se3bv5unmAcWQUV5e3t6WcSYb8bpJjsZc+8oj1766r2YtSpcuzZHDh9j55x9sXL+OiFYtGNS/D9u3b2XowLxj9NZyT/d0lVK78nnsBvIdRNRaz9BaN9ZaN37+pVfza5avuvX9SThxnJOJCaSnp/FTfBxPNQ+0aPN080BWLFsCwLo1q3ikyaMopTh37iwmkwmAxIQTnDj+D9Wq+eDlbeDY30c4d+4sANu3/kKN+2w36L/jLyN+VT2pYXDH1cWJjs3uZ/mWoxZtTqRcIuAh8wzQD/iWp6SbMykXrlKqhAulS5j/rAtqVJ2MTM2BE2etnsN19f0bcPz4PyQmmPdX/Io4AgKDLNo0Dwxi6ZLFAPy0Kp4mjz52yzG1K1cuk5JinsU6IyODTT9v4D/FvL/MeRwjIeEE6WlprIxbTvNceQQEBhG7JAaA1aviaZqVR/PAIFbGLSctLY2EhBMcP34M/wYPcvbsWS5evAjAv//+y5Zff7HIY/WqeJo1D6BEiRLFmtt19epb7qvVK+NolvvYCghkeaz52Fq7Op4mTc05JiYkZJ84O3UykWPHjlK1ajXe7vUey1evJ3bFGkaNGU+TJo8y4pOxVsnnZux9TLegS8YMQChwLtfzCvilWCLCPI70Xv/B9H6rB6bMTMIjoqlZy4+Z0z+nTr36PN08iPCo9gwfOoCOEWG4e3gw/BPzGdY/f9/BV9On4OLignJyot+gYbh7eALwUo83efPl53FxcaFylSoM+WhUcaVQIFOmpvf09Sz9OApnJ8XcVfvYf/wsQ597jN8PGVm+9W8GzNzItF4t6BnVCK3h1QmrAfDyKMXSj6PJzNScPJPKy+PibZYHmPdX/0FDefO1l8k0ZRIZ3Z5afrWZNmUy9er7ExAYRFS7DgwZ2I+IViG4e3gw+tMbV5u0Dgnicupl0tPTWbd2DdNmzMLTw5N3336T9LQ0MrWmcdOmdOjUudjzGDh4GG/0eIXMTBNR0e3x86vN1M8nUb++PwFBLYhu34HBA/oSHhaMu4cHY8d9BoCfX21CwloRHdEaZ2dnBmVd3nY6JZkhgwaQmWkiM1MTEhpG84AbRS5+RRwvvVz4jsnd5Nhv4BDeeeMVTJmZRES1o5Zfbb6YOpm69f1pHhBEZHQHPhjcn+jwUNzdPRg51nylyc4/fmPO7Jm4uLripBT9Bw2z6SWX+bH363TVrc74K6VmAV9rrTfdZN33WuuuBb3BmcsZt5yO+F7k03GqrUMoFmeWvGPrEIqck70fgXcoLcMxx/DdS979RbaPjFh32zXnt6GBVv+A3LKnq7V++RbrCiy4Qghhbfb+e9Zuv5EmhBB3wt6/kSZFVwjhUOQuY0IIYUV2XnOl6AohHIv0dIUQworsvOZK0RVCOBY5kSaEEFYkwwtCCGFFUnSFEMKK7LzmStEVQjgW6ekKIYQV2XnNlaIrhHAs9n71gu3n1hBCiCLkpNRtPwqilApTSh1USh1WSg3Ip00npdQ+pdRepVSBs91KT1cI4VCKanhBKeUMTAWCgQRgu1IqVmu9L0eb2sBA4Emt9TmllHdB25WerhDCoRThzBFNgcNa66Na6zTgRyAyV5tXgala63MAWuvkgjYqRVcI4VCc1O0/cs7nmPXokWNT1YATOZYTsp7L6X7gfqXUZqXUFqVUWEHxFfvwQklX5+J+C6tzxBkWACpGfW7rEIrcmcU9bR1CsXDUGTGKQmFOpGmtZwAz7uLtXIDaQADgA/yslGqgtT6fb3x38WZCCGF3VCH+FSAR8M2x7JP1XE4JQKzWOl1r/TfwF+YinC8pukIIh1KY4YUCbAdqK6XuU0q5AZ2B2FxtFmPu5aKUqoR5uOEotyBXLwghHEpRfSNNa52hlHobiAecgdla671KqeHADq11bNa6EKXUPsAE9NVan7nVdqXoCiEcSlEOd2ut44C4XM8Ny/GzBt7LetwWKbpCCIdi7ycZpegKIRyKvX8NWIquEMKh2HlHV4quEMKxyPCCEEJYkX2XXCm6QggHIzcxF0IIK7Lz82hSdIUQjkWuXhBCCCuS4QUhhLAiO+/oStEVQjgW6ekKIYQV2XfJlaIrhHAwznY+vmC399PdvGkj0W3DiGgdwtdf5b2xe1paGv3f701E6xC6d+3EycQEALb8spmundrRKbotXTu1Y9vWLdmvmTL5M1q1DODJpg9bLY/cNm/aSFR4GBGtQpidX159ehPRKoRuXW7kdf78OV59sTtPNHmY0SOHW7xmyqTPCGsRwBNNbJdXTsGP1GDnl93YM7M773d8JM96X6+yrPykHb9O7sK2KV0JbVwDAFcXJ758tyXbp3Zl6+ddeLpB7plRrKuo99XVq1fp+cZrRLdtRfvIcCZ9Nt5queT0y6aNtGsbRmSbEL6edfO8BvTtTWSbXMfWr5t59pl2dGrXlmefsTy2ruvd8w06Rbct9hxupQjnSCsWdll0TSYTY0YO5/NpM1m4ZBkrVyzn6JHDFm0WL1qAu7s7sXGreLbb89kfYM/y5Zk0ZTrzYpYyfORohg7ql/2aZs0D+eaHeVbNJSeTycToj4czZfpMFsYuY2Xcco7cJK9y7u7ErsjKa4I5rxJuJXizZy96v98vz3abBQTy7Y+2yysnJyfFxDcCiPxgCY3e+C8dm91PHd8KFm36d27Kwo2HePydH+g+ZiWT3gwE4KVQfwCavPU94UMWM/qVp232Pfri2lfdX3yRmKUr+HHBInb+8TubNv5slXyuM5lMjB41nMnTZ7Jg8TLib3FsLVluzmvyxKxjy7M8Ez+fzrxFS/no49EMG2yZ39qfVlGqdGmr5ZIfpW7/YQsFFl2lVB2lVAulVNlczxc4Adud2rN7Fz7Vq+Pj64urqxuhrVqzft0aizbr160hPCIKgBbBoWzf+itaa+rUrYeXtwGAWn61ufbvNdLS0gB4sOFDeHkVOENysdmzexe+ufNamyuvtWtoGxkFQMuQULZl5VWqdGkaPfwIJUq45dmurfPKqcn9Bo6cPM+xpIukZ2Qy/+dDhD9W06KN1hr30uY8PMq4cersZQDqVK/A+p3mXlXKhatcSL3GI7UN1k0gS3Hsq1KlStGk6WMAuLq6UaduPZKNSVbJ57q9e7Ly8jHnFRKW99jasN7y2Np2G8fWlSuX+e+3c3ilxxtWzedmnJS67YdN4rvVSqXUO8ASoCewRymVc/rhUcUVVEqykcqVq2Qvexsqk2w05mqTnN3GxcWFsmXLcf78eYs2a1bHU6duPdzc8hYqW0hONmLIkZfBUJmUZGOuNgXnZc+qVixLwunU7OXE06lUq1jGos3I77bSOfABDs99iZiPInjvi/UA7P47hfDH7sPZSVHD4E4jP298Kln8rrea4t5Xly5e5OcN62j66ONFFvPtSDYaMRhunVeKMTm7ze0eW9OnTOa57i9SsmTJ4k3gNtzrPd1XgUe01lGY5wEaqpTqlbUu35BzTmt8s7Ewazhy+BCTPxvP4A8+ssn7i/x1av4A//1pP37Pzyb6g1hm9QlFKZi7ah+Jp1PZPKkzn/Zoxpb9pzBlaluHW+QyMjIY0K8PXZ7tho+vb8EvsDNHDh9i8sTxDBpmPrYOHthPwonjBLUItnFkZvY+plvQ1QtOWutUAK31MaVUALBAKVWDWxTdnNMaX07ThT5qvLwNJCWdyl5ONibhbTDkauNNUtIpDJUrk5GRQWrqJTw9PQEwJiXR5923GT5qDL6+1Qv79sXG29uAMUdeRmNS9p9rN9rkn9e94OSZVIveabVKZUk8c9mizfMh9YgctgSArQeSKOnmTCX3UqRcuEq/mRuz260b15FDieetEnduxbmvPv5wGNWr1+DZbs8XddgF8jYYMBpvnZeXwRujMf9j6/3ebzN85I1ja9fOP9m3bw/hYUGYMkycPXuWHi91Y8bsb62WV07Odn6dbkE9XaNS6qHrC1kFOByoBDQorqDq+zfgxD//kJiQQHp6GvEr4mgeEGTRpnlAEMtiFwPmP3WaNH0MpRSXLl7knbdeo+e7fXiokX2czb+uvn8Djh+3zCsgMFdegUEsXbIYgJ9WxdPk0cfs/mLvnHb8ZcSvmic1DO64ujjRsVltlm+1nBz1RMolAh4y9/Ae8C1PSVdnUi5cpVQJF0qXMPcDgh7yJcOUyYETZ62eAxTfvpo6eSKXUi/Rd8Cg4gr9lurVtzy2Vq0s3LHV6+3X6NnL8tjq+EwX4tdsZNnKtcya+x01avzHZgUXinQ24GKh9C06okopHyBDa51ntF8p9aTWenNBb3AnPV2ATT9vYNzYUWSaMomIbs8rPV5n+pTJ1KvvT/PAIK5du8bQgf04cGA/Hh4efDJ2Aj6+vnz15XRmz5pB9eo1src17ctZVKhYkYkTPmXl8mWkpCTj5eVNVPsOvP5mz0LHdjc1cOPPGxg3xpxXZHR7XnntdaZl5RWQldeQgf04uH8/7h4ejP50QvafoK1Dgricepn09HTKuZdj2oxZ1Krlx8Txn7Iibhkpycl4eXsT3a4Dr79V+LwqRn1+54nlENq4Bp/2aIazkxNzV+9l7P92MPS5R/n9UDLLt/5NHd8KTHsniDIlXdHA4NmbWfPHcap7l2PpiCgytebkmVTemLiG4ymX7iqWM4sL//9wXVHvq7JlyhLWMoD77quJa9ZY6DNdnqVdh46Fji0z847TYtPGDYwfOwqTKZPIqPa83ON1pk+dTL16OY6tQf04mHVsjRo7AR8fX76aMZ2vv5pB9Ro3jq2pX5iPretOJibw7ttvMC9m6R3FVrbE3fcw3os9cNs1Z0JEHauX3lsW3aJwp0XXnt1DHc9CKaqia0/upujas7spuvasKIpun6UHb7vmjG/7gNWPZvlGmhDCodj5F9Kk6AohHIu9/yUqRVcI4VBc7LzqStEVQjgUO6+5UnSFEI5FpmAXQggrsvOaK0VXCOFY5OoFIYSwInu/ibkUXSGEQ7HzmitFVwjhWJSdz5ImRVcI4VCkpyuEEFYkRVcIIazI3m+FapcTUwohxJ1ydrr9R0GUUmFKqYNKqcNKqQG3aNdeKaWVUo0L2qb0dIUQDqWovpGmlHIGpgLBQAKwXSkVq7Xel6tdOaAXsPW24iuS6IQQwk4U4cwRTYHDWuujWus04Ecg8ibtRgBjgH9vJ75i7+na+fDKHbH3S1LulHHh27YOochVbOqYNzE/s9XxbjhfVApTc5RSPYAeOZ6akTXHI0A14ESOdQnAo7le/zDgq7VerpTqezvvKcMLQgiH4lSITlHOSXQLSynlBEwAXijM66ToCiEcShH+dZ0I+OZY9sl67rpygD+wPuuKicpArFIqQmu9I7+NStEVQjgUl6K7UHc7UFspdR/mYtsZ6Hp9pdb6AuaZ0QFQSq0H3r9VwQU5kSaEcDBK3f7jVrTWGcDbQDywH5intd6rlBqulIq40/ikpyuEcChFeRNzrXUcEJfruWH5tA24nW1K0RVCOBR7v2JKiq4QwqHY+5ipFF0hhEOROdKEEMKKpOgKIYQV2XfJlaIrhHAwdt7RlaIrhHAs9n4/XSm6QgiHIlcvCCGEFcmJNCGEsCIZXhBCCCuS4QUhhLAie+/p2vsvhWybN20kKjyMiFYhzP4q7z2H09LS6N+nNxGtQujWpRMnExMAOH/+HK++2J0nmjzM6JHDrR32LW3e9DOR4aG0bRWcb079+rxL21bBPNelI4k5cnrlxW483qQRn9hJTr9s3kj7iFZEh4cyZ9bMPOvT0tIY2Lc30eGhvPDsM5xMNN+WdO/uXXTtFG1+dIxi3ZrV2a+5dPEi/fv0okNkazpGtWHXzj+slk9uwU/UZWfMUPYs+YD3XwzOs756lfLEfdGTbf8bSPzMXlTz9sxe9/E7keyYP4gd8wfRIeRhK0Z9c5s3bSSqbRgRrW9xLL3fm4jWIXTrmutYeqk7TzTNeyylp6cx4sOhRIaHEt22FT+tjrdKLjejCvGwhXui6JpMJkZ/PJwp02eyMHYZK+OWc+TIYYs2ixctoJy7O7ErVvFst+eZNGE8ACXcSvBmz170fr+fLULPl8lk4pOPhzN1+lcsil3OyrhleXKKWTQfd3d3lq5YzXPdXmDShHGAOae3evbiPTvJyWQyMXbUCCZNm8G8mKWsWrmco7lyWRKzAHd3D2KWxdP1ue58PtGcSy2/2nzz/Xy+nxfD5Gkz+GTEh2RkZAAwfuwoHn/yKRYsieP7+THcd18tq+cG4OSkmDigE5FvT6NR+4/pGPYIdWpWtmjzSe9ovlu+jabPfMKoGSsY3tN857+wp+rzUF1fHu08mmbdxvFu9xaUK1PSFmkAWcfSyOFMmTaThUuWsXLFLY6luKxj6bMcx9LbNz+WvprxBRUqVGTJsngWLlnOI42bWiWfm3FW6rYftnBPFN09u3fhW706Pr6+uLq6EdqqNevXrrFos37tGtpGRgHQMiSUbVt/RWtNqdKlafTwI5Qo4WaDyPNnzqlGjpza3CSntbSNjAZullNj3EqUsEXoeezdswtf3+r4+JhzCQ5rzYb1ay3a/LxuLW0izHP6BQWHsn3bFrTWlCxVChcX8yjXtWtp2X8apl66xB+/7SAyugMArq5ulHN3t2JWNzTx/w9HTpzmWOIZ0jNMzI//nfCABy3a1KlZhQ3bDgKwYftfhAc0AKBuzcps+v0wJlMmV/5NY/ehREKeqGv1HK676bG0Ltfnbt0a2kZEAdAy+CbHklveY2lJzCJeesU81ZiTkxPly5cv9lzyU1T30y0uBRZdpVRTpVSTrJ/rKaXeU0q1Lv7QbkhONmKoXCV72WCoTEqyMVebZCpntXFxcaFs2XKcP3/emmEWSnKykcqVb/SWDAYDyXlyMt4kp3NWjfN2pCQnY8iZi7eBFGPeXAy5crmQtX/27NpJp+hwunSIZMCQD3BxcSExMQHP8hX4aNggnu3Ujo8/HMLVK1esllNOVb09SDDe+H9PNJ6jmpeHRZvdfyUSGfQQAJFBDXEvW4oKHmXY9Ze5yJYq6UpFzzI0b3w/PpVtV5Bueizl2VeFO5YuXbwIwNQpk+jSqR193+vFmdOniz7426QK8c8Wbll0lVIfAJOB6UqpT4ApQBlggFJqsBXiE/8P+D/YkHkxy5j7/TzmzJrJtWvXMJlMHDywjw4dO/PdvEWULFWaObPzjhXbi4GfxfD0I378+kN/nn7Ej0TjOUymTNZsOcDKTftYN6cPcz95ka27/sZkyrR1uEUqw2TCaEyi4UON+GHeIh5s+BCfjR9rs3ju9Z5uB+BJoBnwFhCltR4BhALP5PcipVQPpdQOpdSOmw3UF5a3twFj0qnsZaMxCS9vQ6423iRltcnIyCA19RKenp53/d7FxdvbQFJSUvay0WjEO09OhpvkZLteUn68vL0x5swl2YiXIW8uxly5eOTaP/fVrEXp0qU5cvgQ3gYD3gYD/g82BKBFcAgHD+wr3kTycTL5Aj6GG//v1QzlSUy5YNHmVMoFOr//FY93GcMHU5YCcCH1KgBjZ8XzWOfRhL8xBaUUh44nWy/4XG56LOXZV4U7ljw9PSlZqhQtWoYAEBwaxv79ttlXYJ4N+HYftonv1jK01iat9RXgiNb6IoDW+iqQ769rrfUMrXVjrXXj6+M8d6O+fwOOH/+HxIQE0tPTiF8RR0BgkEWb5oFBLF2yGICfVsXT5NHH7PrSEXNOx0hMOJGV03Ka3zSnGMC+c6pX33L/rF4ZR7PmgRZtng4IZHnsEgDWro6nSVNzLokJCdknzk6dTOTYsaNUrVqNSpW8MBiqcOzY3wBs37qF+2r6WTexLDv2/oNfdS9qVK2Iq4szHUMfZvn6XRZtKnqWyd43fV8KZe6SLYD5JFwFjzIA+Neuin/tqvz06wHrJpBDff8GHP8n17EUkOtzFxDE0tjFAPyUY1/lRylFs+aB7Ni+DYBtW36lZk3bnPQ0x2PfPV2ltc5/pVJbgUCt9RWllJPWOjPreQ9gnda6wOtfrqTf4g0KYePPGxg3ZhSZpkwio9vzymuvM23KZOrV9ycgMIhr164xZGA/Du7fj7uHB6M/nYCPr3n25NYhQVxOvUx6ejrl3MsxbcYsatW68wO4qMaCNv68gU/HjCLTZCIyuj2vvvYG06ZMysqpBdeuXWPwwL7ZOY359LPsnFqFBHE5NTU7p+kzZt9VTgDpd/Fn7+aNG5gw9hNMmZlERLXjpVdf54upk6lb35/mAeb988Hg/hw8sB93dw9Gjh2Pj48vcUuXMGf2TFxcXXFSildee5OAoJYAHDywn5EfDSU9PZ1qPr4MGz4Sd3ePAiKxZHj8nTvOKafQp+rx6fsdcHZSzF2yhbGz4hn6Rht+33ec5Rt2E93yIYb3jEBr2PT7Yd79ZB5p6RmUcHPh1x/6A3Ap9V96jvyRXX8lFvBuBTuz9fM7fu3GnzcwbmyOY6lHPsfSgaxjaWyOYyk0x7FU7saxdPJkIkMG9if10kXKV6jAhyNGUaVK1ULHVtrt7kvh6v2nb7vmBNetZPXSW1DRLaG1vnaT5ysBVbTWuwt6g6IquvbEVgPwxe1uiq69Kqqia2/upujas6IoumsO3H7RbVHH+kX3lt9Iu1nBzXr+NGC705NCCJEPe+8UydeAhRAOxQ5Pe1iQoiuEcCjS0xVCCCtysu+aK0VXCOFY5CbmQghhRfZdcqXoCiEcjPR0hRDCiuy75ErRFUI4GjuvulJ0hRAORYYXhBDCiuy75ErRFUI4GjuvulJ0hRAORb6RJoQQVmTnQ7r3xsSUQghxu4pyCnalVJhS6qBS6rBSasBN1r+nlNqnlNqllFqjlKpR0Dal6AohHIpS6rYfBWzHGZgKtALqAV2UUvVyNfsDaKy1fhBYABQ4OZwUXSGEQynC6XqaAoe11ke11mnAj0BkzgZa63VZ05kBbAF8CtposY/pXv7XVNxvYXUlXR3zd5WdD4XdkTPbHHOGhUqdv7Z1CMXiysKX7nobhfkcK6V6ADkncpyhtb4+m2414ESOdQnAo7fY3MvAioLeU06kCSEcSyGqblaBvespy5VSzwGNgeYFtZWiK4RwKEV4yVgi4Jtj2SfrOcv3U6olMBhont8UZzk55t/JQoj/t4pwTHc7UFspdZ9Syg3oDMRavpdqBHwJRGitk28nPunpCiEcSlFdp6u1zlBKvQ3EA87AbK31XqXUcGCH1joW+BQoC8zPuhriuNY64lbblaIrhHAoRfmNNK11HBCX67lhOX5uWdhtStEVQjgUe/9GmhRdIYRDsfOaK0VXCOFg7LzqStEVQjgUuYm5EEJYkX2XXCm6QghHY+dVV4quEMKhyE3MhRDCiux8SFeKrhDCsdh5zZWiK4RwLAXdnNzWpOgKIRyKnddcKbpCCMdi5zXXfm/tuOWXjXRp14ZnosL4ds7MPOvT0tIYNrAPz0SF8erznTl10nyby1UrlvFC13bZj6eb+HPo4H4Avpw6iXZtWhD8dGOr5pKfXzZvpF1EK6LCQ5kz6+Y5Duzbm6jwUJ5/9hlOJppz3LN7F107RdO1UzRdOkaxbs1qa4eeR3Hk8tGwwQQHPEmndm2tlkdOmzdtJCo8jIhWIcz+Ku99rtPS0ujfpzcRrULo1qUTJxMTADh//hyvvtidJ5o8zOiRwy1eM2XSZ4S1COCJJg9bJYeCBD9UjT8nt2f3lA70iX4wz3qfSmVY8VErfv00kq0Togh9+MZsNP41yrNuVDg7JkazbUIUJVydrRl6/opyZspiYJdF12QyMWHMSMZN/oL/zo/lp/g4/j562KLNsiULKVfOnf8tXskzXbsz/fMJAIS0CmfO94uY8/0ihg4fTZWqPtR+oC4ATzYLYMbcH62ez82YTCbGjBrB5GkzmB+zlPiVyzl6xDLHJTELKOfuweJl8XR9rjufTxwHgJ9fbb75fj7fz4vh82kzGDXiQzIyMmyRBlB8ubSNjOLz6Xd9U/87YjKZGP3xcKZMn8nC2GWsjFvOkVw5LV60gHLu7sSuWMWz3Z5n0oTxAJRwK8GbPXvR+/1+ebbbLCCQb3+cZ5UcCuLkpPjs1ceJGrmKh99dRMenalLHx9OizYAOD7Hol795vO8Snp+wnomvPg6As5NiVq/mvPPlLzR+N4awYStIN2XaIIu8VCH+2UKhi65S6pviCCSn/Xt34+PrSzUfX1xd3WgZ0ppNG9ZZtNm0YS2tws1zxAW0COG3bVvQWlu0+Sk+jhYhrbKX/Rs0pFIlr+IO/7bs3bMLX9/q+GTlGBLWmg3r11q02bBuLeER5hxbBIeyLSvHkqVK4eJiHhm6di3N5icOiiuXhx9pgru7p9XyyGnP7l34Vq+Oj685p9BWrVm/do1Fm/Vr19A2MgqAliGhbNv6K1prSpUuTaOHH6FECbc8232w4UN4eXlbI4UCNfarxJGkixwzXiI9I5MFm44S3qS6RRutNeVKuQLgXtqVU2fNczC2fKgae46dZfc/ZwE4m3qNzEzL489WivAm5sXilmO6SqnY3E8BgUopT4CCbtZ7p1KSjXgbqmQve3kb2LdnV642yXgbKgPg4uJCmbLluHDhPJ6e5bPbrFm1ktHj7XNiwuTkZAyVK2cve3sb2LN7V642RgyVzf8PLi4ulC1bjgvnz+NZvjx7du1k+AeDOXXqFMNHjs4uXLbgSLlclzNeAIOhMnt278zVJpnKuXI6f/485cuX515QtUIZEk9fzl5OPHuZJrUtOyUj//cHscNCeaN1PUqXcCH8o5UA+FVxRwNLhobg5V6S+Zv+5rMlu60Zfr6c7HxQt6Cerg9wEZgAjM96XMrx800ppXoopXYopXZ883Xe8T1r2LtnFyVLlqSmX22bvH9x83+wIfNilvHN9/P4etZMrl0rcGomu+VIuTiajk/X5L/rDlO7x/+IHrmKr95phlLg4uzEE3UMvDRxAy0GLyfi0RoENKhS8Aatwr4HdQsquo2B3zBPunZBa70euKq13qC13pDfi7TWM7TWjbXWjbu/+Gqhg/LyNpBsPJW9nJJsxMvbkKuNN8nGJAAyMjK4nHoJDw/P7PVr4uNoGdq60O9tLd7e3hiTkrKXk5ONeBsMudoYMCaZ/x8yMjJITb2Eh6enRZv7ataidOnSHDl8qNhjzo8j5XJdzngBjMakPJ9Bb29vknLl5JkrJ3t28uxlqlUqk71crUIZTp65YtHm+Rb3s/CXvwHY9lcKJd1cqFSuJIlnLrNpXxJnLl3japqJ+N9P8FDNilaNPz/2Prxwy6Krtc7UWn8GvAgMVkpNwQqXmdWp58+JE8c5mZhAenoaP62K48lmgRZtnmwWyIplSwBYv2YVDzd5NHs8MDMzk7U/xVuM59qbevUbcOL4PyQmmHNctTKOZs0tc2wWEMiyWHOOa1bH06TpYyilSExIyD7ZdOpkIseOHaVq1WpWz+E6R8rluvr+DTieI6f4FXEEBAZZtGkeGMTSJYsB+GlVPE0efczm4+uF8dvh0/hV8aCGd1lcXZzo8FRNlu84btEmIeUygQ+ae7APVPOgpKszKRf/5ac/E/GvUZ5Sbs44Oymeql+FAyfO2yCLvOy7nwsq98mnWzZWqg3wpNZ60O2+JuVSxh2Nrv+66WcmTRhNpimTNhHRPP/ya3z1xefUqVufp5oHce3aNUYMG8Chg/txd/fgw1HjqOZjni359x3b+GLKZ8yY84PFNqdNGsfq+DhOpyRTycub8Mj2vPzaW4WOraRr0Vz0sWnjBiaM/QRTZiYRUe14+dXX+WLqZOrW96d5gDnHYYP7c/CAOcdRY8fj4+PL8qVLmDt7Ji6uriilePW1NwkIKvRUTUWqOHIZ1L8Pv+3Yxvnz56lYoSI93nibqHYdChWXs/OdH1obf97AuDGjyDRlEhndnldee51pUyZTr74/AYHmnIYM7MfB/ftx9/Bg9KcT8PE1fwZbhwRxOfUy6enplHMvx7QZs6hVy4+J4z9lRdwyUpKT8fL2JrpdB15/q2ehY6vU+es7ziun0Id9GPviozg7Kb5Ze4ixC3cytHMjfj98muU7TlDHx5OpbzxJmZKuoDWDv93Omp0nAejcrBbvt3sQrSH+9xMM+XbHXcdzZeFLd10LT11Iu+2aU8XDzeq1t1BF907cadG1Z0VVdEXxu5uia8+Kqujam6IoukkX02+75lR2d7X6B8T2p4mFEKII2fuvWSm6QgiHYu/D6lJ0hRAORW5iLoQQ1mTfNVeKrhDCsdh5zZWiK4RwLDIFuxBCWJGd11z7vLWjEEI4KunpCiEcir33dKXoCiEcilwyJoQQViQ9XSGEsCIpukIIYUUyvCCEEFYkPV0hhLAiO6+5UnSFEA7GzquuFF0hhEOx968BF/vMEdaklOqhtZ5h6ziKmiPm5Yg5gWPm5Yg52ZKjfQ24h60DKCaOmJcj5gSOmZcj5mQzjlZ0hRDCrknRFUIIK3K0ouuo406OmJcj5gSOmZcj5mQzDnUiTQgh7J2j9XSFEMKuSdEVQggrcoiiq5QKU0odVEodVkoNsHU8RUEpNVsplayU2mPrWIqSUspXKbVOKbVPKbVXKdXL1jHdLaVUSaXUNqXUzqycPrJ1TEVJKeWslPpDKbXM1rE4gnu+6CqlnIGpQCugHtBFKVXPtlEViTlAmK2DKAYZQB+tdT3gMeAtB9hf14AgrXVD4CEgTCn1mG1DKlK9gP22DsJR3PNFF2gKHNZaH9VapwE/ApE2jumuaa1/Bs7aOo6iprU+pbX+PevnS5gP5mq2jeruaLPUrEXXrIdDnKFWSvkAbYCvbB2Lo3CEolsNOJFjOYF7/CD+/0Ip9R+gEbDVxqHctaw/wf8EkoHVWut7PqcsE4F+QKaN43AYjlB0xT1IKVUWWAi8q7W+aOt47pbW2qS1fgjwAZoqpfxtHNJdU0qFA8la699sHYsjcYSimwj45lj2yXpO2CmllCvmgvud1nqRreMpSlrr88A6HGM8/kkgQil1DPOwXZBS6r+2Dene5whFdztQWyl1n1LKDegMxNo4JpEPpZQCZgH7tdYTbB1PUVBKeSmlPLN+LgUEAwdsGlQR0FoP1Fr7aK3/g/m4Wqu1fs7GYd3z7vmiq7XOAN4G4jGflJmntd5r26junlLqB+BX4AGlVIJS6mVbx1REngS6Ye41/Zn1aG3roO5SFWCdUmoX5k7Aaq21XF4lbkq+BiyEEFZ0z/d0hRDiXiJFVwghrEiKrhBCWJEUXSGEsCIpukIIYUVSdIUQwoqk6AohhBX9H85/l4N58NuRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.savefig(f\"images/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1087\n",
      "           1       0.93      0.89      0.91      2189\n",
      "           2       0.91      0.89      0.90      2386\n",
      "           3       0.97      0.99      0.98     13158\n",
      "           4       0.89      0.86      0.87      2577\n",
      "\n",
      "    accuracy                           0.94     21397\n",
      "   macro avg       0.91      0.89      0.90     21397\n",
      "weighted avg       0.94      0.94      0.94     21397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train[\"label\"], test[\"label\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
