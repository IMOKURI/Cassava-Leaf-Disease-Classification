{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook  \n",
    "\n",
    "TBD...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"./\"\n",
    "MODEL_DIR = \"../input/cassava-model/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "TRAIN_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "TEST_PATH = \"../input/cassava-leaf-disease-merged/train\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "# TEST_PATH = \"../input/cassava-leaf-disease-classification/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    num_workers = 4\n",
    "    models = [\n",
    "        # \"tf_efficientnet_b3_ns\",\n",
    "        \"tf_efficientnet_b4_ns\",\n",
    "        # \"vit_base_patch16_384\",\n",
    "        # \"deit_base_patch16_384\",\n",
    "        \"seresnext50_32x4d\",\n",
    "    ]\n",
    "    size = {\n",
    "        \"tf_efficientnet_b3_ns\": 512,\n",
    "        \"tf_efficientnet_b4_ns\": 512,\n",
    "        \"vit_base_patch16_384\": 384,\n",
    "        \"deit_base_patch16_384\": 384,\n",
    "        \"seresnext50_32x4d\": 512,\n",
    "    }\n",
    "    batch_size = 32\n",
    "    seed = 22\n",
    "    target_size = 5\n",
    "    target_col = \"label\"\n",
    "    n_fold = 5\n",
    "    trn_fold = {  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        \"tf_efficientnet_b3_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"tf_efficientnet_b4_ns\": {\n",
    "            \"best\": [0, 1, 2, 3, 4],\n",
    "            \"final\": [],\n",
    "        },\n",
    "        \"vit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"deit_base_patch16_384\": {\"best\": [0, 1, 2, 3, 4], \"final\": []},\n",
    "        \"seresnext50_32x4d\": {\"best\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], \"final\": []},\n",
    "    }\n",
    "    data_parallel = {\n",
    "        \"tf_efficientnet_b3_ns\": False,\n",
    "        \"tf_efficientnet_b4_ns\": True,\n",
    "        \"vit_base_patch16_384\": False,\n",
    "        \"deit_base_patch16_384\": False,\n",
    "        \"seresnext50_32x4d\": False,\n",
    "    }\n",
    "    weight = {\n",
    "        # \"tf_efficientnet_b3_ns\": None,\n",
    "        \"tf_efficientnet_b4_ns\": 1,\n",
    "        \"vit_base_patch16_384\": 1,\n",
    "        # \"deit_base_patch16_384\": None,\n",
    "        \"seresnext50_32x4d\": 2,\n",
    "    }\n",
    "    tta = 1  # 1: no TTA, >1: TTA\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sum = sum([CFG.weight[model] for model in CFG.models]) * CFG.tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../input/pytorch-image-models/pytorch-image-models-master\")\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from albumentations import (\n",
    "    CenterCrop,\n",
    "    CoarseDropout,\n",
    "    Compose,\n",
    "    Cutout,\n",
    "    HorizontalFlip,\n",
    "    HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise,\n",
    "    ImageOnlyTransform,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomBrightnessContrast,\n",
    "    RandomContrast,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    Transpose,\n",
    "    VerticalFlip,\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f\"[{name}] start\")\n",
    "    yield\n",
    "    LOGGER.info(f\"[{name}] done in {time.time() - t0:.0f} s.\")\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR + \"inference.log\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  source\n",
       "0  1000015157.jpg      0    2020\n",
       "1  1000201771.jpg      3    2020\n",
       "2   100042118.jpg      1    2020\n",
       "3  1000723321.jpg      1    2020\n",
       "4  1000812911.jpg      3    2020"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "# test = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "test = pd.read_csv(\"../input/cassava-leaf-disease-merged/merged.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df[\"image_id\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f\"{TEST_PATH}/{file_name}\"\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data, size):\n",
    "\n",
    "    if data == \"train\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                ShiftScaleRotate(p=0.5),\n",
    "                HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                CoarseDropout(p=0.5),\n",
    "                Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"valid\":\n",
    "        return Compose(\n",
    "            [\n",
    "                Resize(size, size),\n",
    "                CenterCrop(size, size),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if data == \"inference\":\n",
    "        return Compose(\n",
    "            [\n",
    "                # Resize(size, size),\n",
    "                RandomResizedCrop(size, size),\n",
    "                Transpose(p=0.5),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                # ShiftScaleRotate(p=0.5),\n",
    "                # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "                # RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "                # CoarseDropout(p=0.5),\n",
    "                # Cutout(p=0.5),\n",
    "                Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225],\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnext50_32x4d\", pretrained=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if model_name == \"deit_base_patch16_384\":\n",
    "            # self.model = torch.hub.load(\"facebookresearch/deit:main\", model_name, pretrained=pretrained)\n",
    "            self.model = torch.hub.load(\"../input/fair-deit\", model_name, pretrained=pretrained, source=\"local\")\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "        else:\n",
    "            self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "            if \"resnext50_32x4d\" in model_name:\n",
    "                n_features = self.model.fc.in_features\n",
    "                self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"tf_efficientnet\"):\n",
    "                n_features = self.model.classifier.in_features\n",
    "                self.model.classifier = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "            elif model_name.startswith(\"vit_\"):\n",
    "                n_features = self.model.head.in_features\n",
    "                self.model.head = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "def inference(model, states, test_loader, device, data_parallel):\n",
    "    model.to(device)\n",
    "\n",
    "    # Use multi GPU\n",
    "    if device == torch.device(\"cuda\") and data_parallel:\n",
    "        model = torch.nn.DataParallel(model)  # make parallel\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state[\"model\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to(\"cpu\").numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: tf_efficientnet_b4_ns, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54389a5e88894f40ad5985bae7ba51de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=824.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.4113303  0.16465071 0.19031808 0.01710353 0.21659732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== Model: seresnext50_32x4d, TTA: 0, Saved: best, Fold: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] ==========\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a1471edadd4823adc73b630612d545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=824.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference example: [0.35461578 0.36254448 0.09223738 0.01939635 0.17120597]\n",
      "========== Overall ==========\n",
      "Submission example: [0.3735206  0.29657987 0.12493094 0.01863208 0.18633641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label  source\n",
       "0  1000015157.jpg      0    2020\n",
       "1  1000201771.jpg      3    2020\n",
       "2   100042118.jpg      4    2020\n",
       "3  1000723321.jpg      1    2020\n",
       "4  1000812911.jpg      3    2020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# inference\n",
    "# ====================================================\n",
    "predictions = None\n",
    "for model_name in CFG.models:\n",
    "    for i in range(CFG.tta):\n",
    "        model = CassvaImgClassifier(model_name, pretrained=False)\n",
    "        states = []\n",
    "        for saved_model in [\"best\", \"final\"]:\n",
    "            if CFG.trn_fold[model_name][saved_model] != []:\n",
    "                LOGGER.info(\n",
    "                    f\"========== Model: {model_name}, TTA: {i}, Saved: {saved_model}, Fold: {CFG.trn_fold[model_name][saved_model]} ==========\"\n",
    "                )\n",
    "                states += [\n",
    "                    torch.load(MODEL_DIR + f\"{model_name}_fold{fold}_{saved_model}.pth\")\n",
    "                    for fold in CFG.trn_fold[model_name][saved_model]\n",
    "                ]\n",
    "\n",
    "        if i == 0:  # no TTA\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"valid\", size=CFG.size[model_name]))\n",
    "        else:\n",
    "            test_dataset = TestDataset(test, transform=get_transforms(data=\"inference\", size=CFG.size[model_name]))\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True\n",
    "        )\n",
    "\n",
    "        inf = inference(model, states, test_loader, device, CFG.data_parallel[model_name])\n",
    "\n",
    "        LOGGER.info(f\"Inference example: {inf[0]}\")\n",
    "\n",
    "        if predictions is None:\n",
    "            predictions = inf[np.newaxis] * CFG.weight[model_name]\n",
    "        else:\n",
    "            predictions = np.append(predictions, inf[np.newaxis] * CFG.weight[model_name], axis=0)\n",
    "\n",
    "sub = np.sum(predictions, axis=0) / weight_sum\n",
    "LOGGER.info(f\"========== Overall ==========\")\n",
    "LOGGER.info(f\"Submission example: {sub[0]}\")\n",
    "np.savetxt(f\"{OUTPUT_DIR}/predictions.csv\", sub, delimiter=\",\")\n",
    "\n",
    "# submission\n",
    "test[\"label\"] = sub.argmax(1)\n",
    "test[[\"image_id\", \"label\"]].to_csv(OUTPUT_DIR + \"submission.csv\", index=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "train = pd.read_csv(\"../input/cassava-leaf-disease-merged/merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(train[\"label\"], test[\"label\"])\n",
    "cm = cm / cm.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True, cmap=\"Blues\")\n",
    "plt.savefig(f\"images/{model_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1492\n",
      "           1       0.93      0.90      0.92      3476\n",
      "           2       0.91      0.89      0.90      3017\n",
      "           3       0.97      0.99      0.98     15462\n",
      "           4       0.87      0.87      0.87      2890\n",
      "\n",
      "    accuracy                           0.94     26337\n",
      "   macro avg       0.90      0.88      0.89     26337\n",
      "weighted avg       0.94      0.94      0.94     26337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train[\"label\"], test[\"label\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
